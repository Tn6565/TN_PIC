import os
import requests
import streamlit as st
import pandas as pd
import json
from loguru import logger
import os
from dotenv import load_dotenv
import replicate
import tempfile
import urllib.request

# ç’°å¢ƒå¤‰æ•°ãƒ­ãƒ¼ãƒ‰
load_dotenv()
PIXABAY_API_KEY = os.getenv("TNPIXABAY")
REPLICATE_API_TOKEN = os.getenv("EXTNREPLICATE")

# ---------------- å¸‚å ´åˆ†æ ----------------
def analyze_market(keyword: str):
    """
    Pixabay ã®å†™çœŸï¼ˆphotoï¼‰é™å®šã§å¸‚å ´åˆ†æã‚’è¡Œã†
    """
    logger.info(f"å¸‚å ´ã‚’åˆ†æä¸­: {keyword}")

    url = f"https://pixabay.com/api/?key={PIXABAY_API_KEY}&q={keyword}&image_type=photo&per_page=5"
    response = requests.get(url)

    if response.status_code != 200:
        logger.error(f"Pixabay API ã‚¨ãƒ©ãƒ¼: {response.status_code}")
        return {"error": "Pixabay API ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"}

    data = response.json()

    if "hits" not in data or len(data["hits"]) == 0:
        return {"æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": keyword, "å¸‚å ´å‚¾å‘": "ãƒ‡ãƒ¼ã‚¿ä¸è¶³", "ãƒ’ãƒƒãƒˆä»¶æ•°": 0, "ã‚µãƒ³ãƒ—ãƒ«ç”»åƒ": []}

    # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’æ•´å½¢
    samples = []
    for i, hit in enumerate(data["hits"][:5]):
        samples.append({
            "ç•ªå·": i + 1,
            "ID": hit["id"],
            "ã‚¿ã‚°": ", ".join(hit["tags"].split(",")[:5]),
            "ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼": hit["previewURL"]
        })

    total_results = data.get("totalHits", 0)
    if total_results > 1000:
        trend = "äººæ°—ãŒé«˜ã„"
    elif total_results > 200:
        trend = "å®‰å®š"
    else:
        trend = "ãƒ‹ãƒƒãƒ"

    return {
        "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": keyword,
        "å¸‚å ´å‚¾å‘": trend,
        "ãƒ’ãƒƒãƒˆä»¶æ•°": total_results,
        "ã‚µãƒ³ãƒ—ãƒ«ç”»åƒ": samples
    }

# ---------------- ç”»åƒç”Ÿæˆ ----------------
def generate_image(prompt: str, num_outputs: int = 1, width: int = 512, height: int = 512):
    """stability-ai/stable-diffusion:ac732df83cea7fff18b8472768c88ad041fa750ff7682a21affe81863cbe77e4"""
    try:
        model_id = "stability-ai/stable-diffusion:ac732df83cea7fff18b8472768c88ad041fa750ff7682a21affe81863cbe77e4"
        output = replicate.run(
            model_id,
            input={
                "prompt": prompt,
                "num_outputs": num_outputs,
                "image_dimensions": f"{width}x{height}"
            }
        )
        return output
    except Exception as e:
        logger.error(f"ç”»åƒç”Ÿæˆå¤±æ•—: {e}")
        return None

# ---------------- ç”»åƒä¿å­˜ç”¨ ----------------
def download_image(url, filename):
    tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".png")
    urllib.request.urlretrieve(url, tmp_file.name)
    return tmp_file.name

# ---------------- Streamlit UI ----------------
st.title("ğŸ“Š å¸‚å ´åˆ†æ + ğŸ¨ ç”»åƒç”Ÿæˆ")

keyword = st.text_input("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹: çŒ«ã€çŠ¬ã€é¢¨æ™¯ã€èŠ±ãªã©ï¼‰", "çŒ«")

if st.button("å¸‚å ´åˆ†æé–‹å§‹"):
    result = analyze_market(keyword)

    if "error" in result:
        st.error(result["error"])
    else:
        # çµæœè¡¨ç¤º
        st.subheader(f"ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {result['æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰']}")
        st.write(f"ğŸ“ˆ å¸‚å ´å‚¾å‘: **{result['å¸‚å ´å‚¾å‘']}**")
        st.write(f"ğŸ“Š ãƒ’ãƒƒãƒˆä»¶æ•°: {result['ãƒ’ãƒƒãƒˆä»¶æ•°']} ä»¶")

        st.subheader("ğŸ–¼ ã‚µãƒ³ãƒ—ãƒ«ç”»åƒï¼ˆ5ä»¶ï¼‰")
        cols = st.columns(5)
        for i, sample in enumerate(result["ã‚µãƒ³ãƒ—ãƒ«ç”»åƒ"]):
            with cols[i % 5]:
                st.image(sample["ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"], caption=f"ã‚¿ã‚°: {sample['ã‚¿ã‚°']}", use_column_width=True)

        # ---------------- ä¿å­˜æ©Ÿèƒ½ ----------------
        st.subheader("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ä¿å­˜")

        # JSONä¿å­˜
        json_data = json.dumps(result, ensure_ascii=False, indent=2)
        st.download_button(
            label="ğŸ“¥ JSON ã§ä¿å­˜",
            data=json_data,
            file_name=f"market_analysis_{keyword}.json",
            mime="application/json"
        )

        # CSVä¿å­˜
        df = pd.DataFrame(result["ã‚µãƒ³ãƒ—ãƒ«ç”»åƒ"])
        df.insert(0, "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", result["æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"])
        df.insert(1, "å¸‚å ´å‚¾å‘", result["å¸‚å ´å‚¾å‘"])
        df.insert(2, "ãƒ’ãƒƒãƒˆä»¶æ•°", result["ãƒ’ãƒƒãƒˆä»¶æ•°"])
        csv_data = df.to_csv(index=False)
        st.download_button(
            label="ğŸ“¥ CSV ã§ä¿å­˜",
            data=csv_data,
            file_name=f"market_analysis_{keyword}.csv",
            mime="text/csv"
        )

        # ---------------- ç”»åƒç”Ÿæˆé€£æº ----------------
        st.subheader("ğŸ¨ å¸‚å ´åˆ†æã‹ã‚‰ç”»åƒã‚’ç”Ÿæˆ")

        if st.button("ã“ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ç”»åƒç”Ÿæˆ"):
            with st.spinner("ç”»åƒç”Ÿæˆä¸­..."):
                output_urls = generate_image(keyword, num_outputs=2, width=512, height=512)
                if output_urls:
                    st.success("âœ… ç”»åƒç”ŸæˆæˆåŠŸ")
                    for i, url in enumerate(output_urls):
                        st.image(url, use_column_width=True)
                        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’ä»˜ä¸
                        file_path = download_image(url, f"{keyword}_{i+1}.png")
                        with open(file_path, "rb") as f:
                            st.download_button(
                                label=f"ğŸ“¥ ç”»åƒ{i+1} ã‚’ä¿å­˜",
                                data=f,
                                file_name=f"{keyword}_{i+1}.png",
                                mime="image/png"
                            )
                else:
                    st.error("ç”»åƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

